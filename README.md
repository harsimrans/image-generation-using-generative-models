# Image Generation using Generative Models
Recently Generative models have been very popular and in limelight for synthetic generation of images which look identical to the real-world images. Initially a neural networks is trained which eventually outputs images which gradually with increased training start moving towards looking like real images. 

I've used [Large-scale CelebFaces Attributes (CelebA) Dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). This dataset is over 1.3GB in size and contains more than 200,000 images.
But this isn't limited to just Celeb dataset. You can train this network on any image dataset of size 32x32.

Bottlenecks: The major problem is that I have limited computing capability. With the limited compute power, I had to trim down the images, train for shorter period etc. As we see that with more and more training the GAN seems to be getting good at generating face images. 

# Initial Results

Some of the initial results are given below:

Initially the model think of random noise as faces. A little later it start getting sense of some edges and curves of the face. Gradually with more training, the faces start to atleast look like faces and start improving.

<img src="/gan_img/1.png" width="250"><img src="/gan_img/2.png" width="250"><img src="/gan_img/3.png" width="250"><img src="/gan_img/4.png" width="250"><img src="/gan_img/5.png" width="250">

Given more resource and longer traning time, the results for image generated by GAN should improve. Nevertheless this gives us an idea about how GANs can learn to generate images which eventually resemble real ones.
